# T√≥pico 15 ‚Äì Testes de Hip√≥teses [<img src="images/colag_logo.svg" style="float: right; margin-right: 0%; vertical-align: middle; width: 6.5%;">](https://colab.research.google.com/github/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas/T%C3%B3pico%2015%20%E2%80%93%20Testes%20De%20Hip%C3%B3teses%2F15%20%E2%80%93%20TestesDeHipoteses.ipynb) [<img src="images/github_logo.svg" style="float: right; margin-right: 0%; vertical-align: middle; width: 3.25%;">](https://github.com/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas/T%C3%B3pico%2015%20%E2%80%93%20Testes%20De%20Hip%C3%B3teses%2F15%20%E2%80%93%20TestesDeHipoteses.ipynb)

Nessa aula, voltamos nossa aten√ß√£o para uma pergunta fundamental em Ci√™ncia de Dados: "como testar se um conjunto de hip√≥teses feitas sobre nossos dados √© adequado ou n√£o?".

### Resultados Esperados 

1. Aprender a definir o que s√£o modelos estat√≠sticos, e a formular problemas pr√°ticos em Ci√™ncia de Dados como modelos.
1. Introduzir o conceito de signific√¢ncia estat√≠stica, e a caracteriza√ß√£o da "quantidade de erro aleat√≥rio" que estamos dispostos a permitir em situa√ß√µes pr√°ticas.
1. Introduzir as no√ß√µes b√°sicas de Testes de Hip√≥teses, e a utilizar essa metodologia para testar a adequa√ß√£o de diferentes modelos estat√≠sticos em problemas de an√°lises de dados.

### Refer√™ncias
- [CIT, Cap√≠tulo 11](https://inferentialthinking.com/)

Material adaptado do [DSC10 (UCSD)](https://dsc10.com/) por [Flavio Figueiredo (DCC-UFMG)](https://flaviovdf.io/fcd/) e [Uriel Silva (DEST-UFMG)](https://urielmoreirasilva.github.io)


```python
## Imports para esse t√≥pico (note que aqui temos um novo m√≥dulo nessa lista: o SciPy!)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy as scipy
plt.style.use('ggplot')

## Op√ß√µes de como printar objetos do Numpy e do Pandas
np.set_printoptions(threshold = 20, precision = 2, suppress = True)
pd.set_option("display.max_rows", 7)
pd.set_option("display.max_columns", 8)
pd.set_option("display.precision", 2)
```

## Modelos Estat√≠sticos

### Defini√ß√£o b√°sica

- Informalmente, um **modelo estat√≠stico** consiste de um _conjunto de hip√≥teses_ que fazemos sobre o processo que gerou nossos dados.

Exemplos simples de modelos s√£o:
- Moedas "justas" t√™m probabilidade igual de resultarem em cara ou coroa.
- Dados "justos" t√™m probabilidade igual de resultarem em cada um dos lados.
- A gravidez de uma f√™mea Golden Retriever pode resultar em 1 at√© 14 (!) filhotes, com m√©dia entre 7 e 8.

- Um dos principais objetivos em Infer√™ncia Estat√≠stica √© **aferir a qualidade de um modelo**.
- Em outras palavras, buscamos aferir **o _qu√£o bem_ um modelo explica a "realidade"** refletida nos dados.  

- Conforme aprendemos at√© agora, a maioria dos problemas em Infer√™ncia pode ser resolvido atrav√©s de alguma teoria (baseada em Matem√°tica e Probabilidade), e/ou com t√©cnicas de simula√ß√£o.
- Em ambos os casos, vamos sempre **assumir que o nosso modelo seja verdadeiro**, e ent√£o calcular as frequ√™ncias/probabilidades com as quais os padr√µes observados nos nossos dados ocorreriam sob esse modelo.

- Em geral, o processo de verificar se um modelo √© adequado ou n√£o para um certo conjunto de dados √© denominado de **teste de hip√≥tese**. Definiremos essa no√ß√£o mais formalmente abaixo.

### Exemplo: lan√ßamento de uma moeda

Como exemplo motivador, suponha que queiramos decidir se uma certa moeda √© "justa", isto √©, se no lan√ßamento dessa moeda a probabilidade de uma cara √© igual a probabilidade de uma coroa (1/2, ou 50%).

Para verificar isso, lan√ßamos a moeda $n = 400$ vezes, e anotamos os resultados obtidos.


```python
flips_400 = pd.read_csv('data/flips-400.csv')
flips_400
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>flip</th>
      <th>outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Tails</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Tails</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Tails</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>397</th>
      <td>398</td>
      <td>Heads</td>
    </tr>
    <tr>
      <th>398</th>
      <td>399</td>
      <td>Heads</td>
    </tr>
    <tr>
      <th>399</th>
      <td>400</td>
      <td>Tails</td>
    </tr>
  </tbody>
</table>
<p>400 rows √ó 2 columns</p>
</div>




```python
flips_400.groupby('outcome').count()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>flip</th>
    </tr>
    <tr>
      <th>outcome</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Heads</th>
      <td>188</td>
    </tr>
    <tr>
      <th>Tails</th>
      <td>212</td>
    </tr>
  </tbody>
</table>
</div>



- Naturalmente, podemos ent√£o perguntar: **esse resultado √© consistente ou n√£o** com o nosso "modelo", isto √©, esse resultado condiz com a _hip√≥tese_ de que a moeda √© justa? ü§î
- Em outras palavras, qu√£o _prov√°vel_ (ou _improv√°vel_) seria obtermos 188 caras em 400 lan√ßamentos de uma moeda justa?

## Signific√¢ncia Estat√≠stica

- Antes de introduzirmos o ferramental necess√°rio para responder √† pergunta acima, primeiramente vamos refletir um pouco sobre outro ponto:

> Se esperamos _exatamente_ uma propor√ß√£o de 50% de caras nos lan√ßamentos da moeda do exemplo anterior, quais as propor√ß√µes $p$ de caras aceitar√≠amos como **estatisticamente iguais** a 50%?

> Analogamente, o que nesse caso seria uma "diferen√ßa inaceit√°vel" entre $p$ e 50% para decidirmos que a moeda n√£o √© justa?  

- Para responder perguntas como essa, frequentemente utilizamos o conceito de **signific√¢ncia estat√≠stica**. 

- Basicamente, um resultado √© considerado **estatisticamente significante** se sua ocorr√™ncia por pura chance/aleatoriedade/"coincid√™ncia" √© considerada **baixa**.

- Mais formalmente, um evento √© considerado estatisticamente significante se sua probabilidade √© **menor** do que um certo valor $\alpha \in (0, 1)$.
- Denominamos $\alpha$ ent√£o de **n√≠vel de signific√¢ncia**. Um n√≠vel de signific√¢ncia muito comum utilizado na pr√°tica √© $\alpha = 5\%$.

- O _complementar_ do n√≠vel de signific√¢ncia $\alpha$ √© o n√≠vel de confian√ßa $\gamma$ que vimos anteriormente no T√≥pico 14, isto √©, temos sempre $\alpha + \gamma = 1$.
- Escolher um n√≠vel de signific√¢ncia de $\alpha = 5\%$ √© ent√£o equivalente a escolher um n√≠vel de confian√ßa de $\gamma = 1 - \alpha = 95\%$, por exemplo.

### De volta ao exemplo da moeda

- _Supondo que a moeda seja justa_, qual a probabilidade de ocorrerem entre 188 e 212 caras em $n = 400$ lan√ßamentos?

- Omitindo as tecnicalidades, essa probabilidade pode ser calculada como (lembre do Tri√¢ngulo de Pascal!)

\begin{equation*}
    \sum^{212}_{k = 188} {n \choose k} \left(\frac{1}{2}\right)^k \left(\frac{1}{2}\right)^{n-k} \simeq 0.7888 = 78.88\%
\end{equation*}

- No Python, podemos calcular essa probabilidade atrav√©s da _fun√ß√£o de massa de probabilidade_ da _Distribui√ß√£o Binomial_, `scipy.stats.binom.cdf`.
    - Essa √© outra distribui√ß√£o que voc√™ ver√° nos pr√≥ximos cursos!
    - Os par√¢metros dessa fun√ß√£o s√£o o "n√∫mero de sucessos" `k` $(k = 0, 1, \ldots, n)$, o "n√∫mero de experimentos" `n` $(n \in \mathbb{N})$ e a "probabilidade de sucesso de cada experimento", `p` $(0 < p < 1)$.


```python
prob = 0
n = 400
p = 0.5

for k in np.arange(188, 212 + 1, 1):
    prob = prob + scipy.stats.binom.pmf(int(k), n, p)

round(prob, 4)
```




    0.7888



- Dessa forma, _se a moeda for justa_, a probabilidade de obtermos um n√∫mero de caras entre 188 e 212 √© bem alta!
- Analogamente, a probabilidade de obtermos um n√∫mero de caras **menor** que 188 e **maior** que 212 ser√° ent√£o igual a $1 - 0.7888 \simeq 0.2112$, ou $21.12\%$.


```python
round(1 - 0.7888, 4)
```




    0.2112



- O resultado acima nos diz ent√£o que, ainda que a moeda seja justa, a probabilidade de obtermos algo em torno de 188 a 212 caras em $n = 400$ lan√ßamentos √© _bem razo√°vel_.
- Em outras palavras, como $188/400 = 0.47$ e $212/400 = 0.53$, desvios de at√© $3\%$ na propor√ß√£o esperada de caras ($50\%$) em $n = 400$ lan√ßamentos de uma moeda justa ocorrem com uma probabilidade de $21.12\%$.

- Conclu√≠mos ent√£o que uma ocorr√™ncia de 188 caras em 400 lan√ßamentos **n√£o √© considerada significativa** a um n√≠vel $\alpha = 5\%$!

- Agora, o que seria ent√£o considerado estatisticamente significante nesse problema? ü§î

Se t√≠vessemos observado, por exemplo, 181 caras:


```python
prob = 0
n = 400
p = 0.5

## N√∫mero observado de caras (19 *a menos* ou *a mais* que o "esperado" = 200)
heads_l = 181
heads_u = 219

for k in np.arange(heads_l, heads_u + 1, 1):
    prob = prob + scipy.stats.binom.pmf(int(k), n, p)

round(1 - prob, 4)
```




    0.051



Ainda n√£o!

Talvez 180 caras?


```python
prob = 0
n = 400
p = 0.5

## N√∫mero observado de caras (20 *a menos* ou *a mais* que o "esperado" = 200)
heads_l = 180
heads_u = 220

for k in np.arange(heads_l, heads_u + 1, 1):
    prob = prob + scipy.stats.binom.pmf(int(k), n, p)

round(1 - prob, 4)
```




    0.0402



Agora sim! üëç

- Ao n√≠vel de signific√¢ncia de $\alpha = 5\%$, observar de 181 a 219 caras (isto √©, desvios de at√© 4.75% na propor√ß√£o esperada de caras) ainda seria considerado "aceit√°vel" (isto √©, _n√£o-significante_) nesse caso.
- Precisar√≠amos de um resultado mais _extremo_ (equivalente a desvios maiores ou iguais a 5% na propor√ß√£o esperada de caras) para ser considerado estatisticamente significante, como por exemplo 180 caras ou menos, ou 220 caras ou mais. 

> Para concluir nosso exemplo, lembrando da complementariedade entre o n√≠vel de confian√ßa $\gamma$ e o n√≠vel de signific√¢ncia $\alpha$, podemos obter a _mesma resposta acima_ atrav√©s de um intervalo de 95% de confian√ßa para a propor√ß√£o populacional $p$ de caras em uma moeda justa, que podemos calcular _exatamente_ atrav√©s de:


```python
scipy.stats.binom.interval(0.95, 400, .5)
```




    (180.0, 220.0)



- Voltaremos √† rela√ß√£o entre $\gamma$ e $\alpha$ mais adiante abaixo, mas note que o intervalo e as probabilidades calculados de maneira exata acima s√£o dados aqui apenas para compara√ß√£o. 
- Para os prop√≥sitos desse curso, **vamos calcular todas essas quantidades atrav√©s de simula√ß√£o**! 

### Exerc√≠cio ‚úÖ

Voc√™ acha que o mesmo resultado acima valeria para $n = 40$ ou $n = 4.000$ lan√ßamentos? Por que? Fa√ßa as altera√ß√µes necess√°rias nas c√©lulas de c√≥digo abaixo e comente brevemente sobre os resultados na c√©lula de texto seguinte.

**Importante**: Calcule antes o n√∫mero de caras equivalente a 188 em $n = 400$ quando $n = 40$ e $n = 4.000$.


```python
# ## Descomente e execute!
# prob = 0
# n = ...
# p = 0.5

# for k in np.arange(..., ... + 1, 1):
#     prob = prob + scipy.stats.binom.pmf(int(k), n, p)

# round(prob, 4)
```


```python
# ## Descomente e execute!
# n = ...
# scipy.stats.binom.interval(0.95, n, .5)
```

> ...

## Testes de Hip√≥teses

### No√ß√µes b√°sicas

- Podemos definir um **Teste de Hip√≥teses** como um procedimento em que testamos a **hip√≥tese de que o nosso modelo esteja correto** contra a **hip√≥tese de que o nosso modelo n√£o esteja correto**.
    - A primeira hip√≥tese, isto √©, de que o nosso modelo esteja correto, √© denominada de **hip√≥tese nula**.
    - A segunda hip√≥tese, isto √©, de que o nosso modelo n√£o esteja correto, √© denominada de **hip√≥tese alternativa**.
- A **aceita√ß√£o** de uma hip√≥tese em detrimento da outra leva √† **rejei√ß√£o** da outra hip√≥tese.

- **Muito importante:** Embora estejamos definindo os Testes de Hip√≥teses e nossos modelos em termos como "aceita√ß√£o" e "correto", note que na verdade o procedimento apenas nos diz se o modelo postulado √© _condizente_ com os padr√µes observados nos nossos dados.
- Dessa forma, como em geral o processo gerador dos dados √© _aleat√≥rio_, podemos aceitar a hip√≥tese de um modelo esteja correto (ou errado) por _pura aleatoriedade_, sem que na verdade o modelo seja _verdadeiramente_ correto (ou errado)!
- Essa indetermina√ß√£o √© **inerente √† qualquer processo de decis√£o sob aleatoriedade**, e vale para _todas_ as t√©cnicas que utilizamos em Infer√™ncia Estat√≠stica, exceto em situa√ß√µes triviais.

- Em vista da observa√ß√£o acima, uma outra maneira de pensarmos no n√≠vel de signific√¢ncia √© como um **n√≠vel m√°ximo permitido** para a influ√™ncia da incerteza/aleatoriedade sobre o nosso experimento/processo gerador de dados.
- Equivalentemente, $\alpha$ representa **a frequ√™ncia m√°xima com a qual nosso modelo (ainda que esteja correto) possa ser rejeitado por um teste de hip√≥teses**.

> No exemplo acima, embora 400 lan√ßamentos de uma moeda justa possam _de fato_ produzir menos de 180 caras (ou mais de 220), a _probabilidade_ com a qual isso ocorre √© menor que $\alpha$.

> Reiterando sobre esse ponto, _ainda que nosso modelo esteja correto_, a probabilidade desse resultado ocorrer por pura aleatoriedade √© _t√£o baixa_ que consideramos ser _mais plaus√≠vel_ que nosso modelo esteja errado! 

- Finalmente, como para cada hip√≥tese nula fazemos um teste separado, √© poss√≠vel que **aceitemos v√°rias hip√≥teses nulas diferentes** (e, logo, **v√°rios modelos diferentes**) para os _mesmos dados_.
- Embora existam algumas maneiras de contornar esse problema (voc√™ ver√° isso nos pr√≥ximos cursos!), essa √© uma caracter√≠stica **inerente** √† v√°rias outras t√©cnicas de Infer√™ncia Estat√≠stica.
- N√£o entraremos em mais detalhes, mas lembre da nossa discuss√£o anterior sobre **igualdade estat√≠stica**: com 95% de confian√ßa, todas as propor√ß√µes populacionais $p \in (0.45, 0.55)$ s√£o _igualmente prov√°veis_ (inclusive $p = 0.50$!) nesse experimento.

### Hip√≥teses nulas e alternativas

Vamos agora formalizar as no√ß√µes de hip√≥teses nulas e alternativas introduzidas acima.

- No exemplo da moeda justa, nossa hip√≥tese nula √©: "a moeda √© justa".
- Analogamente, nossa hip√≥tese alternativa √© "a moeda n√£o √© justa".

- Em um teste de hip√≥teses, a hip√≥tese nula deve ser um **modelo de probabilidade bem definido** sobre o processo que gerou nossos dados.
- A raz√£o para isso √© que precisamos poder calcular todas as probabilidades e frequ√™ncias sobre as quais estamos interessados, n√£o s√≥ do ponto de vista _te√≥rico/matem√°tico_, mas tamb√©m do ponto de vista _pr√°tico/computacional_.
- Em outras palavras: precisamos definir bem um modelo para simular desse modelo!
- Usualmente denotamos a hip√≥tese nula por $H_0$.

Mais uma vez voltando ao nosso exemplo, uma poss√≠vel hip√≥tese nula aqui seria $H_0\!\!: p = 0.50$, onde $p$ representa a probabilidade do lan√ßamento de uma moeda resultar em cara (nosso **par√¢metro**).

Tecnicamente, para que esse modelo realmente esteja bem definido, definimos _sob $H_0$_ uma vari√°vel aleat√≥ria $X$ tomando valores no espa√ßo amostral $\{H, T\}$ com probabilidades $p_0 = 0.50$ e $1 - p_0 = 0.50$, respectivamente.

- Por outro lado, a **hip√≥tese alternativa** representa uma _vis√£o diferente_ (e _usualmente_ complementar, para que ent√£o o **teste** tamb√©m esteja bem definido) do processo que gerou nossos dados.
- Dessa forma, a hip√≥tese alternativa **n√£o precisa ser espec√≠fica**, uma vez que basta a hip√≥tese nula _ser rejeitada_ para que a hip√≥tese alternativa _seja aceita_.
- Usualmente denotamos a hip√≥tese alternativa por $H_1$. 

Retornando ao exemplo da moeda, uma poss√≠vel hip√≥tese alternativa seria $H_1\!\!:p \neq 0.50$.

Note que essa √© uma hip√≥tese bem vaga, assim como "a moeda n√£o √© justa", pois _qualquer valor_ para a propor√ß√£o de caras diferente de $p_0 = 0.50$ satisfaz a hip√≥tese alternativa!

### Estat√≠sticas de teste

- Uma vez definidas $H_0$ e $H_1$, come√ßamos ent√£o nossa infer√™ncia **supondo que a hip√≥tese nula $H_0$ seja verdadeira**.

- **Sob $H_0$**, calcularemos uma quantidade que denominaremos de **estat√≠stica de teste** (usualmente denotada por $T$).
- Como o pr√≥prio nome implica, essa ser√° uma **estat√≠stica** (e logo calculada com base na amostra) utilizada para realizarmos nosso teste.
- Em ess√™ncia, a estat√≠stica de teste objetiva medir a evid√™ncia _a favor_ (ou _contra_) $H_0$. 

- Como aqui vamos utilizar simula√ß√£o para conduzir nossos testes, teremos ent√£o _uma estat√≠stica de teste para cada amostra_ produzida sob $H_0$.
- Com base em um n√∫mero grande de amostras, produzimos ent√£o uma aproxima√ß√£o para a distribui√ß√£o de probabilidade da estat√≠stica de teste $T$, isto √©, uma distribui√ß√£o amostral emp√≠rica de $T$.
- Assim, nosso teste basicamente consiste em verificarmos se o valor observado para a nossa estat√≠stica de teste (usualmente denotado por $T_{obs}$) √© _estatisticamente significante_ nessa distribui√ß√£o amostral emp√≠rica.
- De maneira an√°loga como fizemos anteriormente para calcularmos Intervalos de Confian√ßa via Bootstrap, a verifica√ß√£o de signific√¢ncia nesse caso consiste essencialmente em verificar √† _qual percentil dessa distribui√ß√£o_ corresponde o valor de $T_{obs}$!

### Simulando sob $H_0$

- Voltando ao nosso exemplo anterior, podemos simular `n` lan√ßamentos de uma moeda justa utilizando a fun√ß√£o `np.random.binomial(n, 0.5)`.
- O resultado de `np.random.binomial(n, 0.5)` √© equivalente ao de `np.random.multinomial(n, [0.5, 0.5])[0]` que vimos no T√≥pico 11.
- Como estamos interessados na propor√ß√£o de caras, nossa estat√≠stica de teste $T$ ser√° o n√∫mero de caras em cada simula√ß√£o.


```python
np.random.seed(38)
np.random.binomial(400, 0.5)
```




    195




```python
np.random.seed(38)
np.random.multinomial(400, [0.5, 0.5])[0]
```




    195



- Calculamos ent√£o $T$ para cada amostra simulada, anotamos o valor correspondente e, dessa forma, constru√≠mos uma distribui√ß√£o emp√≠rica para a estat√≠stica de teste $T$ sob $H_0$.
- Lembre mais uma vez que aqui _simulamos sob $H_0$_, uma vez que simular sob $H_1$ seria _imposs√≠vel_ (existem infinitos n√£o-enumer√°veis valores de $p_0$ que satisfazem a defini√ß√£o de "moeda injusta").


```python
## Simulando (sob H_0) a distribui√ß√£o de T
# ----

## Fixando a semente aleat√≥ria (para garantir reproducibilidade)
np.random.seed(42)

## Loop principal
results = np.array([])
for i in np.arange(10000):
    result = np.random.binomial(400, 0.5)
    results = np.append(results, result)
results
```




    array([193., 194., 202., ..., 201., 201., 192.])



### Distribui√ß√£o amostral emp√≠rica de T

Vamos agora visualizar a distribui√ß√£o emp√≠rica da estat√≠stica de teste $T$ sob $H_0$:


```python
(pd.DataFrame({"results" : results})
 .plot(kind = 'hist', bins = np.arange(160, 240, 4),
       density = True, ec = 'w', figsize=(10, 5),
       title='Distribui√ß√£o Emp√≠rica do N√∫mero de Caras em $n = 400$ Lan√ßamentos de uma Moeda Justa'));
plt.axvline(188, color = 'black', linewidth = 4, label = 'T_obs = 188')
plt.legend()
plt.ylabel("Densidade");
```


    
![png](15%20%E2%80%93%20TestesDeHipoteses_files/15%20%E2%80%93%20TestesDeHipoteses_67_0.png)
    


- Se t√≠vessemos observado $T'_{obs} = 200$ caras, naturalmente aceitar√≠amos $H_0$, isto √©, a hip√≥tese de que nossa moeda √© justa.

- Analogamente, rejeitar√≠amos $H_0$ (isto √©, concluir√≠amos que nossa moeda √© injusta) se:
    - observ√°ssemos "poucas caras", ou
    - observ√°ssemos "muitas caras".

- Mas como decidimos o que seriam "poucas" e "muitas" nesse contexto? ü§î

### Exerc√≠cio ‚úÖ

Fa√ßa as altera√ß√µes necess√°rias nas c√©lulas de c√≥digo abaixo para simular da distribui√ß√£o da propor√ß√£o de caras $p_{obs}$ sob $H_0$ e visualizar essa distribui√ß√£o em um histograma.


```python
# ## Descomente e execute!

# ## Simulando (sob H_0) a distribui√ß√£o de T
# # ----

# ## Fixando a semente aleat√≥ria (para garantir reproducibilidade)
# np.random.seed(42)

# ## Loop principal
# results = np.array([])
# for i in np.arange(10000):
#     result = np.random.binomial(400, 0.5)/...
#     results = np.append(results, result)
# results
```


```python
# ## Descomente e execute!
# (pd.DataFrame({"results" : results})
#  .plot(kind = 'hist', bins = np.arange(160/..., 240/..., 4/...),,
#        density = True, ec = 'w', figsize = (10, 5),
#        title='Distribui√ß√£o Emp√≠rica da Propor√ß√£o de Caras em $n = 400$ Lan√ßamentos de uma Moeda Justa'));
# plt.axvline(188/..., color = 'black', linewidth = 4, label = 'p_obs = ...')
# plt.legend()
# plt.ylabel("Densidade");
```

### Valores Cr√≠ticos e Regi√µes de Aceita√ß√£o

- Dada a nossa discuss√£o acima sob signific√¢ncia estat√≠stica, seria natural **rejeitarmos $H_0$ se a probabilidade de observarmos $T_{obs}$ for muito baixa**.

- No exemplo anterior, vimos (teoricamente) que a probabilidade de que $T \leq 180$ ou que $T \geq 220$ √© pouco menor que 5%.
- Dessa forma, valores **t√£o extremos** quanto $T \leq 180$ ou $T \geq 220$ s√£o considerados **estatisticamente significantes** (ao n√≠vel de $\alpha = 5\%$), e logo _indicativos_ de que $H_0$ n√£o √© verdadeira.

Na distribui√ß√£o simulada anteriormente, podemos encontrar esses valores como os percentis 2.5% e 97.5% da distribui√ß√£o emp√≠rica de $T$, respectivamente:


```python
np.percentile(results, 2.5)
```




    180.0




```python
np.percentile(results, 97.5)
```




    220.0



- Ao n√≠vel de $\alpha = 5\%$ de signific√¢ncia, dizemos ent√£o que $c_1 = 180$ e $c_2 = 220$ s√£o os **n√≠veis cr√≠ticos** (ou valores cr√≠ticos) desse teste de hip√≥teses.

- Mais formalmente, os **n√≠veis cr√≠ticos** de um teste s√£o valores $c_1 < c_2$ tais que

> **$H_0$ √© rejeitada ao n√≠vel $\alpha\%$ de signific√¢ncia** caso $T_{obs} < c_1$ _ou_ $T_{obs} > c_2$

ou, equivalentemente,

> **$H_0$ √© aceita ao n√≠vel $\alpha\%$ de signific√¢ncia** caso $T_{obs} \geq c_1$ _e_ $T_{obs} \leq c_2$, ou simplesmente se $c_1 \leq T_{obs} \leq c_2$.

Note que formalmente sempre frisamos "ao n√≠vel $\alpha\%$ de signific√¢ncia", pois os n√≠veis cr√≠ticos $c_1$ e $c_2$ ser√£o _sempre_ fun√ß√µes de $\alpha$.

- Quando simulamos a distribui√ß√£o de $T$ sob $H_0$, $c_1$ e $c_2$ aqui s√£o simplesmente dados pelos percentis $\alpha/2$ e $1 - \alpha/2$ dessa distribui√ß√£o.
- Analogamente, se utilizarmos alguma teoria ou aproxima√ß√£o, $c_1$ e $c_2$ ser√£o dados pelos mesmos percentis da distribui√ß√£o correspondente (por exemplo a Binomial).

- Na nomenclatura usual de Testes de Hip√≥teses, o conjunto de pontos entre $c_1$ e $c_2$ definem a **Regi√£o de Aceita√ß√£o** do teste.
- Formalmente, $RA := \{T_{obs} \!: c_1 \leq T_{obs} \leq c_2\}$.
- Como o pr√≥prio nome implica, _aceitamos $H_0$ para todos os valores_ $T_{obs} \in RA$.

- Em contrapartida, o conjunto de pontos menores que $c_1$ e maiores que $c_2$ definem a **Regi√£o de Rejei√ß√£o** (ou _Regi√£o Cr√≠tica_) do teste.
- Formalmente, $RC := \{T_{obs} \!: T_{obs} < c_1 \,\text{ou}\,\,\, T_{obs} > c_2\}$.
- Como o pr√≥prio nome implica, _rejeitamos $H_0$ para todos os valores_ $T_{obs} \in RC$.

- Finalmente, como aqui s√≥ existem 2 resultados para um teste de hip√≥teses (isto √©, _ou aceitamos ou rejeitamos_ $H_0$), ent√£o $RA$ e $RC$ s√£o _exatamente complementares_, isto √©,

\begin{equation*}
    T_{obs} \in RA \Leftrightarrow T_{obs} \notin RC
\end{equation*}

e vice-versa.

### Testes de Hip√≥teses via Intervalos de Confian√ßa

- Uma outra maneira de interpretar a Regi√£o de Aceita√ß√£o conforme definida acima √© como um conjunto de pontos em que os valores observados para uma certa estat√≠stica de teste $T$ s√£o _estatisticamente iguais_ sob $H_0$.

- No nosso exemplo, todas as propor√ß√µes de caras observadas entre $c_1/400 = 180/400 = 0.45$ e $c_2/400 = 220/400 = 0.55$ s√£o _igualmente prov√°veis_, e consistentes (para essa amostra, de tamanho $n = 400$) com $H_0\!\!: p = 0.50$.
- Essa interpreta√ß√£o √© muito similar √† de um Intervalo de Confian√ßa!

- De fato, **existe uma rela√ß√£o natural, direta e intr√≠nseca entre os Testes de Hip√≥teses e Intervalos de Confian√ßa**.
  
> Mais especificamente, lembrando que $\gamma = 1 -\alpha$, um IC de $\gamma\%$ para o par√¢metro de interesse **sempre cont√©m todos os valores hipotetizados para o par√¢metro de interesse que levariam √† aceita√ß√£o de $H_0$!**.

#### IC exato via Distribui√ß√£o Binomial

Retornando ao exemplo anterior, temos $T_{obs} = 188$ em $n = 400$ lan√ßamentos da moeda.

Utilizando propriedades da distribui√ß√£o Binomial, o IC de 95% de confian√ßa _exato_ para o _n√∫mero de caras_ √© dado por


```python
T_obs = 188
n = 400
gamma = 0.95
```


```python
scipy.stats.binom.interval(gamma, n, T_obs/n)
```




    (168.0, 208.0)



Por outro lado, $T_{obs} = 188$ em $n = 400$ lan√ßamentos se traduz em uma propor√ß√£o de caras estimada igual a $p_{obs} = 0.47$:


```python
p_obs = T_obs/n
p_obs
```




    0.47



Dessa forma, o IC de 95% de confian√ßa an√°logo para a propor√ß√£o de caras √© ent√£o dado por


```python
CI = scipy.stats.binom.interval(gamma, n, p_obs)
left = CI[0]/n
right = CI[1]/n

[left, right]
```




    [0.42, 0.52]



**Nota**: o IC acima para a propor√ß√£o $p$ √© apenas uma _transforma√ß√£o_ do IC para o n√∫mero de caras, e logo ambos ICs devem sempre levar **√†s mesmas conclus√µes**! 

#### IC via simula√ß√£o

Podemos calcular o IC de 95% de confian√ßa acima tamb√©m _via simula√ß√£o_.

Basta proceder como fizemos anteriormente, mas _simulando sob $p_{obs} = 0.47$_:


```python
## Simulando a distribui√ß√£o de T sob p = 0.47
# ----

# Fixando a semente aleat√≥ria (para garantir reproducibilidade)
np.random.seed(42)

## Loop principal
results_CI = np.array([])
for i in np.arange(10000):
    result_CI = np.random.binomial(400, 0.47)
    results_CI = np.append(results_CI, result_CI)

## IC95%
L_CI = np.percentile(results_CI, 2.5)
U_CI = np.percentile(results_CI, 97.5)
```

O IC95% constru√≠do por simula√ß√£o para o n√∫mero de caras √© ent√£o dado por:


```python
[L_CI, U_CI]
```




    [168.0, 208.0]



e o IC95% correspondente para a propor√ß√£o de caras √©:


```python
[L_CI/n, U_CI/n]
```




    [0.42, 0.52]



Note que ambos ICs (via distribui√ß√£o Binomial e via simula√ß√£o) s√£o _exatamente iguais_! üëç

- Conclu√≠mos dessa forma que, embora a propor√ß√£o de caras observada $p_{obs} = 0.47$ n√£o tenha sido _exatamente_ (ou _numericamente_) igual a $p_0 = 0.50$, podemos afirmar, com 95% de confian√ßa, que $p_{obs}$ √© _estatisticamente igual_ a $p_0$, uma vez que ambos os valores est√£o contidos dentro do IC95%.
- Analogamente, para essa amostra, **qualquer hip√≥tese do tipo $H_0\!\!: p = p_0$ para $p_0 \in [0.42, 0.52]$ seria aceita** ao n√≠vel $\alpha = 5\%$!

#### E o bootstrap? ü§î

Ainda uma outra maneira de construir um IC95% via simula√ß√£o nesse caso √© realizando um _bootstrap_ com base na nossa amostra original, `flips_400`:


```python
## Aproximando a distribui√ß√£o de T via boostrap
# ----

# Fixando a semente aleat√≥ria (para garantir reproducibilidade)
np.random.seed(42)

## Loop principal
results_boot = np.array([])
for i in np.arange(10000):
    result_boot = np.sum(flips_400['outcome'].sample(400, replace = True) == "Heads")
    results_boot = np.append(results_boot, result_boot)

## IC95%
L = np.percentile(results_boot, 2.5)
U = np.percentile(results_boot, 97.5)
```


```python
[L, U]
```




    [169.0, 207.0]



Assim como fizemos anteriormente, via bootstrap podemos tamb√©m aproximar a distribui√ß√£o amostral da propor√ß√£o de caras, e dessa forma tamb√©m calcular seu IC95% an√°logo:


```python
[L/n, U/n]
```




    [0.4225, 0.5175]



**Importante**: Tanto a constru√ß√£o da distribui√ß√£o de $T$ sob $H_0$ quanto a constru√ß√£o do IC95% sob $p_{obs} = 0{,}47$ s√£o feitas com base **no mesmo modelo**, isto √©, com base na distribui√ß√£o Binomial.

- Dessa forma, denominamos em geral ambas as t√©cnicas de **param√©tricas**, pois pressup√µe que os dados v√™m de uma distribui√ß√£o _espec√≠fica_ (no caso a Binomial) com **par√¢metros** espec√≠ficos (no caso $n = 400$ e $p = 0{,}50$, ou $p = 0{,}47$).
- Dessa forma, como ressaltado acima, **os resultados de ambos os m√©todos t√™m que levar √†s mesmas conclus√µes**!

Por outro lado, a constru√ß√£o da distribui√ß√£o amostral emp√≠rica de $T$ feita com base no bootstrap ü•æ **n√£o pressup√µe** nenhum modelo espec√≠fico ‚Äì _utilizamos apenas a amostra_, que nesse caso pode ent√£o vir de qualquer popula√ß√£o! 

- Dizemos ent√£o em geral que o bootstrap √© uma t√©cnica **n√£o-param√©trica**, pois n√£o pressup√µe praticamente nada sobre a distribui√ß√£o populacional dos dados.
- Como consequ√™ncia, as conclus√µes baseadas nos resultados do boostrap _podem sim ser diferentes_ dos resultados dos m√©todos acima, **pois as hip√≥teses sob as quais esses m√©todos est√£o baseados s√£o diferentes**!

Em resumo, √© importante sempre prestar aten√ß√£o √†s hip√≥teses que est√£o sendo feitas sobre os dados e m√©todos, pois somente assim podemos garantir uma coer√™ncia entre eles.

- Note inclusive que aqui n√£o conseguimos conduzir um teste de hip√≥teses "diretamente" atrav√©s do bootstrap como fizemos acima com base no modelo param√©trico.
    - Lembre que sem um modelo (param√©trico) **bem definido** como base, n√£o conseguimos simular sob $H_0$!

### p-valores

- As regras de aceita√ß√£o/rejei√ß√£o de $H_0$ definidas acima s√£o **bin√°rias** e, logo, "r√≠gidas".
- Em outras palavras, _ou aceitamos ou rejeitamos_ $H_0$, e isso ocorre de maneira _independente_ do "qu√£o distante" a estat√≠stica de teste $T_{obs}$ se encontra dos pontos cr√≠ticos $c_1$ e $c_2$!

- Nesse contexto, frequentemente surgem perguntas do tipo: dado que $H_0$ √© rejeitada para $T_{obs}$, o qu√£o "extremo" √© o valor de $T_{obs}$?
- Em termos precisos, qual a probabilidade de obtermos de um valor de $T_{obs}$ _mais distante_ (na dire√ß√£o de $H_1$) de $c_1$, ou $c_2$?
- A quantifica√ß√£o dessa "dist√¢ncia" em termos de frequ√™ncia/probabilidade √© dada por uma quantidade que denominamos de **p-valor**.

- Mais precisamente, um p-valor $\hat{\alpha}$ √© definido como **a probabilidade (sob $H_0$) da nossa estat√≠stica de teste $T$ ser menor/maior do que o valor observado $T_{obs}$**, **_na dire√ß√£o em que rejeitamos $H_0$_ (isto √©, na dire√ß√£o de $H_1$)**.

No exemplo anterior, como a distribui√ß√£o de $T$ sob $H_0$ est√° centrada em $m = 200$ e nossa hip√≥tese nula diz respeito ao fato da moeda ser justa, temos $c_1 = 180$, $c_2 = 220$, e:

- se $T_{obs} < m$, ent√£o $\hat{\alpha}$ √© dado pela soma da **cauda √† esquerda de $T_{obs}$** com a **cauda √† direita de $2m - T_{obs}$** da distribui√ß√£o de $T$ sob $H_0$.
- se $T_{obs} > m$, ent√£o $\hat{\alpha}$ √© dado pela soma da **cauda √† esquerda de $2m - T_{obs}$** com a **cauda √† direita de $T_{obs}$** da distribui√ß√£o de $T$ sob $H_0$.

Para calcular esse valor, basta calcularmos as frequ√™ncias correspondentes na distribui√ß√£o de $T$ simulada sob $H_0$:  


```python
T_obs = 188
m = 200
p_lower = np.count_nonzero(results < T_obs) / len(results)
p_upper = np.count_nonzero(results > 2*m - T_obs) / len(results)
p = p_lower + p_upper
p
```




    0.2148



Naturalmente, como os percentis 2.5 e 97.5 da nossa distribui√ß√£o simulada para $T$ sob $H_0$ s√£o $c_1 = 180$ e $c_2 = 220$, **qualquer valor de $T_{obs}$ tal que $T_{obs} < c_1$ ou $T_{obs} > c_2$ ter√° um p-valor menor que $\alpha = 5\%$!**


```python
T_obs = 181
m = 200
p_lower = np.count_nonzero(results < T_obs) / len(results)
p_upper = np.count_nonzero(results > 2*m - T_obs) / len(results)
p = p_lower + p_upper
p
```




    0.055099999999999996




```python
## Note aqui a maneira de calcular os p-valores √© invertida, pois T_obs >= m!.
T_obs = 219
m = 200
p_lower = np.count_nonzero(results < 2*m - T_obs) / len(results)
p_upper = np.count_nonzero(results > T_obs) / len(results)
p = p_lower + p_upper
p
```




    0.055099999999999996




```python
T_obs = 180
m = 200
p_lower = np.count_nonzero(results < T_obs) / len(results)
p_upper = np.count_nonzero(results > 2*m - T_obs) / len(results)
p = p_lower + p_upper
p
```




    0.0435




```python
T_obs = 220
m = 200
p_lower = np.count_nonzero(results < 2*m - T_obs) / len(results)
p_upper = np.count_nonzero(results > T_obs) / len(results)
p = p_lower + p_upper
p
```




    0.0435



Note que essas probabilidades s√£o muito similares √†s calculadas exatamente (atrav√©s da distribui√ß√£o Binomial) no in√≠cio dessa aula!

### Exerc√≠cio ‚úÖ

Altere as c√©lulas de c√≥digo abaixo para encontrar os valores de $T_{obs}$ necess√°rios para rejeitarmos $H_0$ caso t√≠vessemos escolhido $\alpha = 10\%$ e $\alpha = 20\%$. Preencha tamb√©m a c√©lula de texto seguinte com o porque voc√™ acha razo√°vel que esses valores de $T_{obs}$ sejam maiores/menores do que os valores para rejeitar $H_0$ ao n√≠vel de $\alpha = 5\%$, tendo em mente a conex√£o entre $\alpha$ e o n√≠vel de confian√ßa $\gamma$.


```python
# ## Descomente e execute!
# T_obs = ...
# m = 200
# p_lower = np.count_nonzero(results < T_obs) / len(results)
# p_upper = np.count_nonzero(results > 2*m - T_obs) / len(results)
# p = p_lower + p_upper
# p
```


```python
# ## Descomente e execute!
# T_obs = ...
# m = 200
# p_lower = np.count_nonzero(results < T_obs) / len(results)
# p_upper = np.count_nonzero(results > 2*m - T_obs) / len(results)
# p = p_lower + p_upper
# p
```

> ...

#### Utilizando os p-valores

- O resultado acima pode ser enunciado em geral da seguinte forma:

> **se $T_{obs} \in RA$, ent√£o $\hat{\alpha} \geq \alpha$**.

ou, analogamente,

> **se $T_{obs} \notin RA$, ent√£o $\hat{\alpha} \leq \alpha$**.

- Dessa forma, **podemos utilizar o p-valor diretamente para conduzir um teste de hip√≥teses**, pois
    - se $\hat{\alpha} \geq \alpha$, ent√£o $T_{obs} \in RA$ e aceitamos $H_0$;
    - se $\hat{\alpha} < \alpha$, ent√£o $T_{obs} \notin RA$ e rejeitamos $H_0$.

Note que a possibilidade de que $p = \alpha$ n√£o ocorre na pr√°tica, pois $0 < p < 1$ √© um n√∫mero real.

Tecnicamente, esse √© um _evento que ocorre com probabilidade zero_ ‚Äì voc√™ ver√° mais sobre isso em outros cursos!

- Finalmente, tendo em vista o argumento acima, √© comum denominarmos o p-valor $\hat{\alpha}$ de _n√≠vel de signific√¢ncia emp√≠rico_ ou _observado_, pois **dado $T = T_{obs}$, o p-valor √© igual _ao menor valor de $\alpha$ tal que $H_0$ seja rejeitada_**.

#### Controv√©rsias sobre os p-valores

- Existe [_muita_](https://en.wikipedia.org/wiki/Misuse_of_p-values) controv√©rsia em torno do uso de p-valores na condu√ß√£o de Testes de Hip√≥teses, e a principal fonte de controv√©rsia √© dada ao tentar interpretar o p-valor como uma probabilidade.


- Da defini√ß√£o de n√≠vel signific√¢ncia observado acima, note que embora _calculemos_ o p-valor como uma probabilidade, $\hat{\alpha}$ depende de um _valor observado_ na amostra, isto √©, de $T_{obs}$.

> Dessa forma, o p-valor √© na verdade uma **estat√≠stica**, e **n√£o uma probabilidade**!

- Embora esse ponto seja bem sutil e ser√° elaborado (repetidamente) de maneira cada vez mais detalhada nos pr√≥ximos cursos, √© importante lembrar que, como _o processo de amostragem √© aleat√≥rio_, **um valor mais/menos extremo de $T_{obs}$ n√£o significa uma evid√™ncia mais/menos forte contra $H_0$**, pois flutua√ß√µes nos valores de $T$ s√£o _naturalmente esperadas devido √† aleatoriedade_.

- Finalmente, embora o p-valor seja muito √∫til para caracterizar melhor as quantidades envolvidas em um Teste de Hip√≥teses (e logo dar mais interpretabilidade aos resultados obtidos), **no fim das contas _aceitar ou rejeitar_ $H_0$ √© _sempre uma decis√£o bin√°ria_**!

### Conclus√µes de um Teste de Hip√≥teses

- Com base no teste de hip√≥tese realizado no exemplo anterior, a diferen√ßa de $p_{obs} - p_0 = -0.03$ observada no nosso processo de amostragem pode ent√£o, _ao n√≠vel de signific√¢ncia de $\alpha = 5\%$_, **ser puramente atribu√≠da ao acaso**!
- Como o teste que constru√≠mos √© _sim√©trico_, uma diferen√ßa de $p_0 - p_{obs} = 0.03$ tamb√©m n√£o seria considerada estatisticamente significante.

- Em geral, _qualquer valor_ de $p_{obs}$ no intervalo $RA = [0.45, 0.55]$ que fosse observado para essa amostra de tamanho $n = 400$ seria consistente com a hip√≥tese de que a moeda √© justa.
- Analogamente, valores de $p_{obs}$ menores que $0.45$ ou maiores que $0.55$ (ou diferen√ßas maiores que $0.05$ em m√≥dulo) seriam considerados estatisticamente significantes e, logo, n√£o seriam consistentes com $H_0$ ao n√≠vel de $\alpha = 5\%$ de signific√¢ncia.

- O IC95% complementa a conclus√£o acima com a informa√ß√£o de que, para essa amostra, _qualquer valor_ $p_0$ no intervalo $[0.42, 0.52]$ seria plaus√≠vel como a propor√ß√£o _real_ de caras obtidas em um lan√ßamento dessa moeda.
- Naturalmente, isso inclui o valor $p_0 = 0.50$!

Podemos ent√£o tamb√©m dizer, com 95% de confian√ßa, que a moeda √© justa, uma vez que a propor√ß√£o $p_0 = 0.50$ se encontra dentro do IC95%.

- Finalmente, o p-valor do teste de $\hat{\alpha} = 21.48\%$ nos diz que um resultado como $T_{obs} = 188$ caras, ou uma propor√ß√£o de $p_{obs} = 0.47$ em $n = 400$ lan√ßamentos de _uma moeda justa_ (isto √©, sob $H_0$), **n√£o √© t√£o at√≠pico** assim.

**N√£o podemos dizer ent√£o que esse √© um resultado significante**, e logo **n√£o rejeitamos $H_0$**, pois a probabilidade de obtermos um resultado como esse por puro acaso √© de 21.48%, o que ao n√≠vel $\alpha = 5\%$ √© considerado aceit√°vel.

### Exerc√≠cio ‚úÖ

Fa√ßa as altera√ß√µes necess√°rias nas c√©lulas de c√≥digo abaixo para 

1. simular da distribui√ß√£o de $T$ sob $H_0$,
1. visualizar essa distribui√ß√£o em um histograma,
1. e calcular o p-valor do teste,

mas agora supondo $n = 40$ e $n = 4.000$.

Suas conclus√µes s√£o as mesmas para $n = 400$, isto √©, aceitamos ou rejeitamos $H_0$ nesses casos? Escreva sua resposta na c√©lula de texto seguinte e comente brevemente sobre o porque voc√™ acha que isso acontece.

_<ins> Dica</ins>_: embora o valor de $T_{obs}$ seja diferente para diferentes valores de $n$, estamos supondo aqui que o valor de $p_{obs} = 0{,}47$ continua igual!


```python
# ## Descomente e execute!
# n = ...

# ## Simulando (sob H_0) a distribui√ß√£o de T
# # ----

# ## Fixando a semente aleat√≥ria (para garantir reproducibilidade)
# np.random.seed(42)

# ## Loop principal
# results = np.array([])
# for i in np.arange(10000):
#     result = np.random.binomial(n, 0.5)
#     results = np.append(results, result)
# results
```


```python
# ## Descomente e execute!
# (pd.DataFrame({"results" : results})
#  .plot(kind = 'hist', bins = 20,
#        density = True, ec = 'w', figsize=(10, 5),
#        title=f'Distribui√ß√£o Emp√≠rica do N√∫mero de Caras em $n = {n}$ Lan√ßamentos de uma Moeda Justa'));
# plt.axvline(0.47*n, color = 'black', linewidth = 4, label = f'T_obs = {0.47*n}')
# plt.legend()
# plt.ylabel("Densidade");
```


```python
# ## Descomente e execute!
# T_obs = 0.47*n
# m = n/2
# p_lower = np.count_nonzero(results < T_obs) / len(results)
# p_upper = np.count_nonzero(results > 2*m - T_obs) / len(results)
# p = p_lower + p_upper
# p
```

> ...

## Resumo

- Um modelo estat√≠stico pode ser formulado como um conjunto de hip√≥teses que elaboramos sobre o processo que gerou nossos dados.
- Para verificar a adequa√ß√£o de um modelo estat√≠stico, realizamos um **Teste de Hip√≥teses**, em que testamos uma hip√≥tese nula $H_0$ contra uma hip√≥tese alternativa $H_1$.
- A **hip√≥tese nula** $H_0$ deve ser um modelo de probabilidade bem definido sobre o processo gerador de dados.
- A **hip√≥tese alternativa** $H_1$ pode ser menos precisa, e usualmente representa o complementar de $H_0$.
- Se aceitamos/rejeitamos $H_0$, ent√£o rejeitamos/aceitamos $H_1$, e vice-versa.

Um Teste de Hip√≥teses √© tipicamente conduzido da seguinte maneira:

1. Aproximamos a distribui√ß√£o de uma **estat√≠stica de teste** $T$ sob $H_0$ atrav√©s de simula√ß√£o;
1. Analisamos se, nessa distribui√ß√£o, a ocorr√™ncia do valor observado para a nossa estat√≠stica de teste $T_{obs}$ por pura chance/aleatoriedade √© "alta" ou "baixa", de acordo com algum **n√≠vel de signific√¢ncia** $\alpha$ pr√©-definido.

- Existe uma rela√ß√£o intr√≠nseca entre Testes de Hip√≥teses com n√≠vel de signific√¢ncia $\alpha$ e Intervalos de Confian√ßa com n√≠vel de confian√ßa $\gamma = 1- \alpha$.
- Em particular, conclus√µes tomadas com base em ambas as t√©cnicas **devem ser estritamente as mesmas**.

- Um **p-valor** $\hat{\alpha}$ √© uma maneira de quantificar, sob $H_0$, o qu√£o _extremo_ √© o valor de $T_{obs}$.
- Podemos formular nossas conclus√µes em um Teste de Hip√≥teses apenas com base nos p-valores, mas devemos tomar cuidado ao interpret√°-los!
