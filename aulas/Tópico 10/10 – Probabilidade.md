# TÃ³pico 10 â€“ Probabilidade [<img src="images/colag_logo.svg" style="float: right; vertical-align: middle; width: 42px; height: 42px;">](https://colab.research.google.com/github/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas/T%C3%B3pico%2010/10%20%E2%80%93%20Probabilidade.ipynb) [<img src="images/github_logo.svg" style="float: right; margin-right: 12px; vertical-align: middle; width: 36px; height: 36px;">](https://github.com/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas/T%C3%B3pico%2010/10%20%E2%80%93%20Probabilidade.ipynb)

Vamos aprender o bÃ¡sico da Teoria de Probabilidade.

### Resultados Esperados

1. Introduzir os conceitos de espaÃ§o amostral, eventos, massa e densidade de probabilidade.
1. Aprender algumas propriedades bÃ¡sicas de probabilidade.
1. Introduzir os conceitos de probabilidade condicional e independÃªncia.

### ReferÃªncias
- [CIT, CapÃ­tulo 9](https://inferentialthinking.com/)

Material adaptado do [DSC10 (UCSD)](https://dsc10.com/) por [Flavio Figueiredo (DCC-UFMG)](https://flaviovdf.io/fcd/) e [Uriel Silva (DEST-UFMG)](https://urielmoreirasilva.github.io)

## Probabilidade

- Algumas coisas na vida sÃ£o _naturalmente_ aleatÃ³rias.
- Por exemplo, quando lanÃ§amos uma moeda ou um dado ğŸ², nÃ£o sabemos o resultado de antemÃ£o, entÃ£o podemos dizer que esse resultado Ã© _incerto_, ou _aleatÃ³rio_.
- PorÃ©m, ainda que um resultado em particular seja incerto, podemos estudar a _regularidade_ com as quais certos resultados acontecem atravÃ©s da **Teoria de Probabilidade**.

- Novamente tomando como exemplo o lanÃ§amento de uma moeda "honesta", a **probabilidade** de observamos "cara" Ã© igual a probabilidade de observarmos "coroa", e ambas sÃ£o iguais a $\frac{1}{2}$.
- Outro exemplo Ã© o lanÃ§amento de um lado de 6 faces: a probabilidade com que cada face ocorre Ã© de $\frac{1}{6}$.

- Apesar da Probabilidade ser uma Ã¡rea da EstatÃ­stica/MatemÃ¡tica muito bem definida em termos formais, Ã© natural que busquemos diferentes _interpretaÃ§Ãµes_ para o que uma probabilidade realmente _representa_.
- A interpretaÃ§Ã£o "clÃ¡ssica" ou **frequentista** nos diz que, se pudÃ©ssemos repetir um **experimento aleatÃ³rio** infinitas vezes, a **frequÃªncia** com a qual um resultado ocorre Ã© sua probabilidade de ocorrÃªncia.
- Por outro lado, a interpretaÃ§Ã£o "subjetiva" ou **Bayesiana** nos diz que a probabilidade de ocorrÃªncia de um resultado Ã© **diferente para cada indivÃ­duo**, e depende do quÃ£o **provÃ¡vel** (ou **improvÃ¡vel**) esse resultado Ã© relativo a todos os outros possÃ­veis resultados do experimento em questÃ£o.

- Nesse curso, adotaremos a interpretaÃ§Ã£o frequentista, e utilizaremos **frequÃªncias relativas para estimar probabilidades**!
    - Veremos isso com mais detalhes nos TÃ³picos 11 e 12.

### Terminologia bÃ¡sica

**Experimento aleatÃ³rio**: Um processo ou aÃ§Ã£o cujo resultado Ã© aleatÃ³rio.

- Exemplos:
    - lanÃ§amento de um dado;
    - lanÃ§amento de uma moeda duas vezes;
    - ocorrÃªncia de chuva no dia de hoje;
    - vitÃ³ria do Galo na Libertadores 2024.

**EspaÃ§o amostral**: O conjunto de todos os resultados possÃ­veis de um experimento aleatÃ³rio.

- NotaÃ§Ã£o: utilizamos $\Omega$ para denotar o espaÃ§o amostral.

- Exemplos:
    - $\Omega = \{1, 2, 3, 4, 5, 6\}$;
    - $\Omega = \{(H, H), (H, T), (T, H), (T, T)\}$;
    - $\Omega = \{\text{chove}, \text{nÃ£o chove}\}$;
    - $\Omega = \{\text{vitÃ³ria}, \text{derrota}\}$.

**Evento**: um conjunto especÃ­fico de resultados de interesse do experimento aleatÃ³rio. 

- NotaÃ§Ã£o: utilizamos $A$ para denotar um evento. Escrevemos $A \subseteq \Omega$, pois formalmente $A$ Ã© um _subconjunto_ de $\Omega$.

- Exemplos:
    - $A = \text{``nÃºmero par''} = \{2, 4, 6\}$;
    - $A = \text{``pelo menos 1 cara''} = \{(H, H), (H, T), (T, H)\}$;
    - $A = \text{``chove e vou me molhar''} = \{ \}$;
    - $A = \text{``felicidade da naÃ§Ã£o atleticana''} = \{ \text{vitÃ³ria} \}$.

**Probabilidade**: um nÃºmero entre 0 e 1 (equivalentemente, entre 0% e 100%) que descreve a probabilidade de um evento.

- NotaÃ§Ã£o: utilizamos $P(A)$ para denotar a probabilidade de um evento $A$. Temos sempre $P(A) \in [0, 1]$.

- Exemplos:
    - $P(A) = 1/2 = 0.50 = 50\%$;
    - $P(A) = 3/4 = 0.75 = 75\%$;
    - $P(A) = 0 = 0\%$;
    - $P(A) = \,?$

- Nota: o evento $A = \{ \}$ Ã© denominado **evento impossÃ­vel**, pois $P(\{ \}) = 0$.
- Analogamente, o evento $A = \Omega$ Ã© denominado **evento certo**, pois $P(\Omega) = 1$.

### Resultados igualmente provÃ¡veis

- Se todos os resultados do espaÃ§o amostral $\Omega$ forem _equiprovÃ¡veis_ (isto Ã©, igualmente provÃ¡veis), entÃ£o a probabilidade de qualquer evento $A \subseteq \Omega$ Ã© dada por

\begin{equation*}
    P(A) = \frac{\# \text{de elementos em } A}{\# \text{de elementos em } \Omega} = \frac{\#(A)}{\#(\Omega)}
\end{equation*}

#### Exemplo

- Suponha que lancemos uma moeda "justa" 3 vezes. Qual Ã© a probabilidade de vermos exatamente 2 caras?

O espaÃ§o amostral nesse exemplo Ã© dado por $\Omega = \{(H, H, H), (H, H, T), (H, T, H), (H, T, T), (T, H, H), (T, H, T), (T, T, H), (T, T, T)\}$. 

Nosso evento de interesse Ã© $A = \{(H, H, T), (H, T, H), (T, H, H)\}$.

Dessa forma, como $\#(A) = 3$ e $\#(\Omega) = 2^3 = 8$, entÃ£o $P(A) = 3/8$.

### ExercÃ­cio âœ…

Suponha que vocÃª tenha trÃªs cartas: uma vermelha, uma azul e outra verde. 

Qual Ã© a probabilidade de vocÃª escolher uma das cartas aleatoriamente e ela ser verde, e entÃ£o â€“ **sem devolvÃª-la** â€“ vocÃª escolher outra carta aleatoriamente e ela ser vermelha?

A. $\frac{1}{9}$

B. $\frac{1}{6}$

C. $\frac{1}{3}$

D. $\frac{2}{3}$

E Nenhuma das opÃ§Ãµes acima.

### Eventos mutuamente exclusivos

- Suponha que $A$ e $B$ sejam dois eventos **mutuamente exclusivos**.
- Isso significa que se $A$ acontecer, $B$ nÃ£o acontece, e vice-versa.
- Na linguagem de Teoria de Conjuntos, dizemos que $A$ e $B$ sÃ£o _disjuntos_, isto Ã©, _nÃ£o existe interseÃ§Ã£o entre $A$ e $B$_.
- Formalmente, escrevemos $A \cap B = \{ \}$.

- Quando $A$ e $B$ sÃ£o mutuamente exclusivos, Ã© razoÃ¡vel que a probabilidade de que o evento $\text{``} A \text{ ou } B \text{''}$ ocorra seja igual a **soma das probabilidades** de ocorrÃªncia de $A$ e $B$.
- Intuitivamente, $\text{``} A \text{ ou } B \text{''} = A \cup B$.
- Essa regra Ã© denominada de **regra da adiÃ§Ã£o**.

Mais precisamente, a regra da adiÃ§Ã£o diz que, para $A \cap B = \{ \}$,
\begin{equation*}
    P(A \text{ ou } B) = P(A) + P(B)
\end{equation*}

#### Exemplo

- Suponha que estejamos analisando o lanÃ§amento de um dado de 6 faces. Qual Ã© a probabilidade de obtermos um 5 **ou** um 6?

O espaÃ§o amostral nesse exemplo Ã© dado por $\Omega = \{1, 2, 3, 4, 5, 6\}$. 

Nossos eventos de interesse sÃ£o $A = \{ 5 \}$ e $B = \{ 6 \}$.

Dessa forma, como $A \cap B = \{ \}$, $A$ e $B$ sÃ£o mutuamente exclusivos, e $P(A \text{ ou } B) = P(A) + P(B)$.

Como todos os resultados sÃ£o igualmente provÃ¡veis e $\#(\Omega) = 6$, entÃ£o $P(A) = \#(A) / \#(\Omega) = 1/6$ e $P(B) = \#(B) / \#(\Omega) = 1/6$.

Finalmente, aplicando a regra da adiÃ§Ã£o, chegamos a $P(A \text{ ou } B) = P(A) + P(B) = 1/6 + 1/6 = 2/6 = 1/3$.

### Eventos complementares

- Suponha agora que estejamos interessados na probabilidade de que um evento $A$ **nÃ£o aconteÃ§a**.
- Em Teoria dos Conjuntos, denominamos tais eventos de **complementares**.
- O complementar de $A$ (em $\Omega$) Ã© definido como $A^c$.
- Formalmente, denotamos $\text{``} A \text{ nÃ£o ocorrer} \text{''} \equiv A^c$.

- Podemos provar, utilizando a regra da adiÃ§Ã£o, que
\begin{equation*}
    P(\text{``} A \text{ nÃ£o ocorrer} \text{''}) := P(A^c) = 1 - P(A)
\end{equation*}

- O resultado acima Ã© intuitivo, uma vez que os eventos $A$ e $\text{``} A \text{ nÃ£o ocorrer} \text{''}$ sÃ£o mutuamente exclusivos, e como um ou o outro _sempre_ ocorrem, a soma de suas probabilidades Ã© igual a 1.

#### Exemplo

- Suponha que $A = \{\text{chover hoje}\}$, e que $P(A) = 20\%$. EntÃ£o $A^c = \{\text{nÃ£o chover hoje}\}$, e $P(\text{``} A \text{ nÃ£o ocorrer} \text{''}) = P(A^c) = 1 - P(A) = 80\%$.

### Eventos simultÃ¢neos

- Suponha agora que estejamos interessados na probabilidade de que **ambos** $A$ e $B$ ocorram.
- O evento de interesse aqui pode ser entÃ£o denotado como $\text{``} A \text{ e } B \text{''}$.
- Intuitivamente, $\text{``} A \text{ e } B \text{''} = A \cap B$.
- Ã‰ comum denotarmos $P(\text{``} A \text{ e } B \text{''}) = P(A, B)$.

#### Exemplo

- Suponha que vocÃª lance um dado de 6 faces. Qual Ã© a probabilidade de o lanÃ§amento ser igual a 3 ou menos, e ainda por cima um nÃºmero par?

O espaÃ§o amostral nesse exemplo Ã© dado por $\Omega = \{1, 2, 3, 4, 5, 6\}$. 

Nossos eventos de interesse sÃ£o $A = \{ 1, 2, 3 \}$ e $B = \{ 2, 4, 6 \}$.

Dessa forma, temos $\text{``} A \text{ e } B \text{''} = A \cap B = \{ 2 \}$.

Como todos os resultados sÃ£o igualmente provÃ¡veis e $\#(\Omega) = 6$, entÃ£o $P(A \cap B) = \#(A \cap B) / \#(\Omega) = 1/6$.

### Probabilidade Condicional

- Suponha agora que estejamos interessados na probabilidade de que $B$ ocorra, sabendo que $A$ jÃ¡ ocorreu.
- Nesse contexto, definimos a **probabilidade condicional** de $B$ dado $A$ por:

\begin{equation*}
P(\text{``} B \text{ dado } A \text{''}) \equiv P(B | A) := \frac{P(A, B)}{P(A)}
\end{equation*}

- Na probabilidade condicional de $B$ dado $A$, "restringimos" o espaÃ§o amostral $\Omega$ a ser igual aos elementos contidos em $A$.
- Em outras palavras, o conhecimento da ocorrÃªncia de $A$ **aumenta** a probabilidade de ocorrÃªncia de $P(A, B)$, uma vez que aqui temos **mais informaÃ§Ã£o** e logo **menos incerteza**.

- Para ilustrar esse ponto formalmente, note que se todos os elementos de $\Omega$ forem equiprovÃ¡veis, temos que
\begin{equation*}
    P(B|A) = \frac{P(A, B)}{P(A)} = \frac{\frac{\#(A \cap B)}{\#(\Omega)}}{\frac{\#(A)}{\#(\Omega)}} = \frac{\#(A \cap B)}{\#(\Omega)} \cdot \frac{\#(\Omega)}{\#(A)} = \frac{\#(A \cap B)}{\#(A)}
\end{equation*}
o que corrobora nossa intuiÃ§Ã£o de que $A$ se torna o "novo espaÃ§o amostral" quando condicionamos em sua ocorrÃªncia.

### ExercÃ­cio âœ…

Suponha que vocÃª lance um dado de 6 lados e sabe apenas que o resultado Ã© igual a 3 ou menos. Qual Ã© a probabilidade de que o resultado seja um nÃºmero par?

A. $\frac{1}{2}$

B. $\frac{1}{3}$

C. $\frac{1}{4}$

D. Nenhuma das opÃ§Ãµes acima.

### A regra da multiplicaÃ§Ã£o

- A **regra da multiplicaÃ§Ã£o** nos fornece uma maneira de calcular a probabilidade de ocorrÃªncia de ambos $A$ e $B$, sabendo qual Ã© a probabilidade **marginal** de $A$ e qual Ã© a probabilidade condicional de $B$ dado $A$.
- Mais especificamente, 

\begin{equation*}
    P(A, B) = P(A) \cdot P(B | A)
\end{equation*}

#### Exemplo (de novo!)

- Suponha que vocÃª lance um dado de 6 faces. Qual Ã© a probabilidade de o lanÃ§amento ser igual a 3 ou menos, e ainda por cima um nÃºmero par?

O espaÃ§o amostral nesse exemplo Ã© dado por $\Omega = \{1, 2, 3, 4, 5, 6\}$. 

Nossos eventos de interesse sÃ£o $A = \{ 1, 2, 3 \}$ e $B = \{ 2, 4, 6 \}$.

Sabemos que $P(A) = 1/2$ e que $P(B|A) = 1/3$.

Logo, utilizando a regra da multiplicaÃ§Ã£o, $P(A, B) = 1/2 \cdot 1/3 = 1/6$, assim como obtivemos anteriormente.

### Eventos independentes

- A noÃ§Ã£o de **eventos independentes** surge naturalmente no contexto de Probabilidade Condicional quando fazemos a seguinte pergunta:

> "e se a ocorrÃªncia de $A$ nÃ£o afetar a ocorrÃªncia de $B$? ğŸ¤”"

- Formalmente, dois eventos $A$ e $B$ sÃ£o independentes se
\begin{equation*}
    P(B | A) = P(B)
\end{equation*}

- Agora, pela regra da multiplicaÃ§Ã£o, note que isso implica que
\begin{equation*}
    P(A, B) = P(A) \cdot P(B)
\end{equation*}

- Em geral, ambas as definiÃ§Ãµes sÃ£o vÃ¡lidas para eventos independentes, mas a consequÃªncia de ambas Ã© a mesma: se $A$ e $B$ sÃ£o independentes, $P(B|A) = P(B)$ e $P(A|B) = P(A)$, de maneira que **o conhecimento da ocorrÃªncia de um evento nÃ£o impacta a probabilidade do outro**.

#### Exemplo

- Suponha que lancemos uma moeda justa repetidas vezes, de maneira independente uma da outra. Qual Ã© a probabilidade de observarmos 50 caras seguidas?

O espaÃ§o amostral de _cada lanÃ§amento_ nesse exemplo Ã© dado por $\Omega_i = \{H, T\}$, $i = 1, \ldots, 50$.

Nosso evento de interesse Ã© $(A_1, A_2, \ldots, A_{50})$, onde cada $A_i = \{ H \}$. 

Cada $A_i$ tÃªm probabilidade igual a $P(A_i) = 1/2$.

Como os $A_i$ sÃ£o independentes, entÃ£o $P(A_1, A_2, \ldots, A_{50}) = (\frac{1}{2})^{50}$.

### ExercÃ­cio âœ…

Suponha que cada vez que vocÃª liga para sua avÃ³ ğŸ‘µ, a probabilidade de ela atender o telefone Ã© de $\frac{1}{3}$, independentemente se ela atendeu o telefone ou nÃ£o na Ãºltima ligaÃ§Ã£o. Se vocÃª ligar trÃªs vezes para sua avÃ³ hoje, qual a chance de vocÃª conseguir falar com ela exatamente trÃªs vezes?

_Dica_: utilize a independÃªncia e a complementariedade dos eventos.

A. $\frac{1}{3}$

B. $\frac{1}{9}$

C. $\frac{1}{27}$

D. $1$

E. Nenhuma das opÃ§Ãµes acima.

### Booleanos

- A Teoria de Probabilidade Ã© _intrinsicamente_ ligada Ã  Teoria dos Conjuntos.
- Como vimos anteriormente, as operaÃ§Ãµes entre variÃ¡veis booleanas tambÃ©m sÃ£o naturalmente formuladas como operaÃ§Ãµes entre conjuntos.
- Na prÃ¡tica, Ã© muito comum definirmos os eventos sobre os quais estamos interessados atravÃ©s de operaÃ§Ãµes entre booleanas nos nossos `arrays`, `DataFrames`, `Series`, `Lists`, etc; veremos isso mais adiante nos prÃ³ximos tÃ³picos.

## Resumo

- O conjunto de todos os possÃ­veis resultados de um experimento aleatÃ³rio Ã© denominado de **espaÃ§o amostral**.
- Um **evento** Ã© uma coleÃ§Ã£o de elementos de interesse do espaÃ§o amostral. 
- A **probabilidade** de ocorrÃªncia de um evento pode ser interpretada como a **frequÃªncia** com a qual esse evento ocorreria caso pudÃ©ssemos repetir o experimento aleatÃ³rio infinitas vezes.
- Existem vÃ¡rias regras para calcular probabilidades. Nesse curso analisaremos muitos casos especiais em que os elementos do espaÃ§o amostral sÃ£o igualmente provÃ¡veis.
- Duas regras Ãºteis para o cÃ¡lculo das probabilidades de certos eventos sÃ£o:
    1. A **regra da adiÃ§Ã£o**, que afirma que para quaisquer dois eventos **mutuamente exclusivos**, $P(A \text{ ou } B) = P(A) + P(B)$;
    1. A **regra da multiplicaÃ§Ã£o**, que afirma que para quaisquer dois eventos, $P(A, B) = P(B | A) \cdot P(A) \:$.
