# T√≥pico 16 ‚Äì Padroniza√ß√£o [<img src="images/colag_logo.svg" style="float: right; margin-right: 0%; vertical-align: middle; width: 6.5%;">](https://colab.research.google.com/github/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas%2FT%C3%B3pico%2016%20%E2%80%93%20Padroniza%C3%A7%C3%A3o%2F16%20%E2%80%93%20Padronizacao.ipynb) [<img src="images/github_logo.svg" style="float: right; margin-right: 0%; vertical-align: middle; width: 3.25%;">](https://github.com/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas%2FT%C3%B3pico%2016%20%E2%80%93%20Padroniza%C3%A7%C3%A3o%2F16%20%E2%80%93%20Padronizacao.ipynb)

Nesta aula, vamos introduzir e explorar o conceito de padroniza√ß√£o, e motivar a import√¢ncia de se padronizar certos conjuntos de vari√°veis para uma an√°lise mais coerente.

### Resultados Esperados

1. Formalizar apropriadamente os conceitos de M√©dia, Mediana, Desvio Padr√£o e Vari√¢ncia.
1. Expandir a no√ß√£o de como as estat√≠sticas descritivas podem ser utilizadas para descrever uma distribui√ß√£o de interesse.
1. Introduzir o conceito de padroniza√ß√£o e aprender a interpretar estat√≠sticas calculadas em unidades padronizadas.

### Refer√™ncias
- [CIT, Cap√≠tulo 14](https://inferentialthinking.com/)

Material adaptado do [DSC10 (UCSD)](https://dsc10.com/) por [Flavio Figueiredo (DCC-UFMG)](https://flaviovdf.io/fcd/) e [Uriel Silva (DEST-UFMG)](https://urielmoreirasilva.github.io)


```python
## Imports para esse t√≥pico
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.style.use('ggplot')

## Op√ß√µes de como printar objetos do Numpy e do Pandas
np.set_printoptions(threshold = 20, precision = 2, suppress = True)
pd.set_option("display.max_rows", 7)
pd.set_option("display.max_columns", 8)
pd.set_option("display.precision", 2)
```

## Recapitulando: Infer√™ncia Estat√≠stica

### O que aprendemos at√© agora

At√© agora, na segunda parte do curso focamos em **Infer√™ncia Estat√≠stica**, que aqui definimos como o ato de tirar conclus√µes sobre uma popula√ß√£o com base em uma amostra.

- Para obter uma **estimativa pontual** de um par√¢metro populacional, utilizamos alguma estat√≠stica apropriada.
    - Para quantificar a incerteza sobre nossa estimativa, utilizamos bootstrap para construir **Intervalos de Confian√ßa**, que s√£o **estimativas intervalares** para o nosso par√¢metro. 

- Para testar se algum par√¢metro populacional de interesse √© igual a um certo valor com base em uma amostra, realizamos **Testes de Hip√≥teses**.
    - Existe uma rela√ß√£o intr√≠nseca entre Testes de Hip√≥teses e Intervalos de Confian√ßa, e esses √∫ltimos tamb√©m podem ser utilizados para verificar se o valor hipotetizado para o par√¢metro de interesse √© compat√≠vel com nossa amostra.

### O que vamos ver adiante

- At√© o final do curso, nosso foco de agora em diante ser√° em realizar **previs√µes**.
    - Isto √©, com base em uma amostra, podemos dizer algo sobre a parte da popula√ß√£o que **n√£o est√° na amostra**? ü§î

- Mais especificamente, vamos nos ater √† **regress√£o linear**, uma t√©cnica de predi√ß√£o que tenta encontrar a "melhor rela√ß√£o linear" entre duas ou mais vari√°veis num√©ricas.
    - Voc√™ fatalmente trabalhar√° com regress√£o linear (e n√£o-linear!) em muitos outros cursos. Essa √© uma das ferramentas mais √∫teis em Ci√™ncia de Dados.

## Interl√∫dio: Medidas de Tend√™ncia Central e Dispers√£o

- At√© agora, utilizamos rotineiramente fun√ß√µes como a m√©dia e a  mediana, aplicando essas fun√ß√µes tanto em amostras quanto popula√ß√µes.
- Por√©m, antes de seguir com o resto do material, precisamos formalizar essas defini√ß√µes, e introduzir outras medidas que utilizaremos para caracterizar uma distribui√ß√£o de interesse.
    - Denominamos essas medidas de **estat√≠sticas descritivas**.

### Medidas de Tend√™ncia Central

- Uma medida de **tend√™ncia central** descreve _onde_ (ou seja, ao redor de qual valor) uma distribui√ß√£o est√° centralizada.
- Medidas de tend√™ncia central s√£o muitas vezes denominadas de _par√¢metros de loca√ß√£o_ de uma distribui√ß√£o.
- A intui√ß√£o por tr√°s dessa nomenclatura vem do fato de que as distribui√ß√µes em geral t√™m padr√µes de variabilidade _em torno_ das medidas de tend√™ncia central, o que √© equivalente a dizer que uma distribui√ß√£o est√° _localizada_ em torno do seu centro.
    - At√© agora, j√° vimos duas medidas de tend√™ncia central: a **m√©dia** e a **mediana**.

#### Exemplo: Atrasos de v√¥os ‚úàÔ∏è


```python
delays = pd.read_csv('data/united_summer2015.csv')
delays.plot(kind = 'hist', y = 'Delay', bins = np.arange(-20.5, 210, 5), density = True, ec = 'w', figsize = (10, 5))
plt.title('Atrasos de V√¥os')
plt.xlabel('Atrasos (em minutos)')
plt.ylabel("Densidade");
```


    
![png](16%20%E2%80%93%20Padronizacao_files/16%20%E2%80%93%20Padronizacao_14_0.png)
    


**Pergunta**: Qual √© maior na distribui√ß√£o dos atrasos de v√¥os: a m√©dia ou a mediana?


```python
delays['Delay'].mean()
```




    16.658155515370705




```python
delays['Delay'].median()
```




    2.0




```python
delays.plot(kind = 'hist', y = 'Delay', bins = np.arange(-20.5, 210, 5), density = True, ec = 'w', alpha = 0.65, figsize = (10, 5))
plt.plot([delays['Delay'].mean(), delays['Delay'].mean()], [0, 1], color = 'green', label = 'Mean', linewidth = 2)
plt.scatter([delays['Delay'].mean()], [-0.0017], color = 'green', marker = '^', s = 250)
plt.plot([delays['Delay'].median(), delays['Delay'].median()], [0, 1], color = 'purple', label = 'Median', linewidth = 2)
plt.title('Atrasos de V√¥os')
plt.xlabel('Atrasos (em minutos)')
plt.ylim(-0.005, 0.065)
plt.legend()
plt.ylabel("Frequ√™ncia");
```


    
![png](16%20%E2%80%93%20Padronizacao_files/16%20%E2%80%93%20Padronizacao_18_0.png)
    


#### M√©dia

- **Defini√ß√£o**: Soma de todos os elementos da amostra, dividida pelo tamanho amostral $n$.
    - √â comum denotarmos a m√©dia _populacional_ por $\mu$ e a m√©dia _amostral_ por $\bar{X}$.
    - Denotando nosso conjunto de observa√ß√µes por $\boldsymbol{X} := (X_1, \ldots, X_n)$, definimos ent√£o $\bar{X} := \frac{1}{n} \sum^n_{i=1} X_i$.

- Visualmente, a m√©dia amostral pode ser pensada como o "ponto de equil√≠brio" de uma distribui√ß√£o.
    - A soma das diferen√ßas entre cada ponto e a m√©dia √© sempre igual a 0.
    - Uma analogia √© pensar na m√©dia amostral como o ponto de apoio de uma gangorra.

#### Mediana

- **Defini√ß√£o**: Ponto que divide a amostra ao meio.
    - Metade da distribui√ß√£o est√° √† direita da mediana, e a outra metade √† esquerda.
    - Usualmente denotamos a mediana populacional por $med(\boldsymbol{X})$, e a mediana amostral por $\widehat{med}(\boldsymbol{X})$.

- A mediana √© o percentil 50 de uma distribui√ß√£o.
- Se uma distribui√ß√£o √© **sim√©trica** em torno de um valor, ent√£o esse valor coincide com _ambas_ m√©dia e mediana.
- Se uma distribui√ß√£o √© **assim√©trica** (_√† direita_ ou _√† esquerda_), ent√£o a m√©dia ser√° diferente da mediana (respectivamente, √† direita ou √† esquerda, de acordo com a dire√ß√£o da assimetria).

> **Propriedade importante**: A mediana √© mais **robusta** (menos **sens√≠vel**) a **_outliers_/valores extremos/valores discrepantes** que a m√©dia.

### Exerc√≠cio ‚úÖ

Considere os seguintes histogramas, correspondentes a duas distribui√ß√µes diferentes:

<center>
    <table><tr>
        <td> <center><img src = "images/hist.jpg" width = 70%></center>  </td>
        <td> <center><img src = "images/hist2.jpg" width = 70%></center> </td>
    </tr></table>
</center>

Preencha agora a c√©lula de texto abaixo com a alternativa **correta** relativa √†s distribui√ß√µes acima:

**A**. Ambas m√©dia e mediana s√£o iguais.

**B**. As m√©dias s√£o diferentes, mas as medianas s√£o iguais.

**C**. As m√©dias s√£o iguais, mas as medianas s√£o diferentes.

**D**. Ambas m√©dia e mediana s√£o diferentes.

### Medidas de Dispers√£o

#### Desvio Padr√£o

**Pergunta**: Como caracterizamos a "largura" de uma distribui√ß√£o? ü§î

- Uma ideia natural seria tomarmos o maior valor e subtrair pelo menor valor encontrado na distribui√ß√£o.
    - Essa medida √© conhecida como a **amplitude** (_range_, em ingl√™s) da distribui√ß√£o.
    - Apesar de intuitiva, a amplitude n√£o nos diz muito sobre a _forma_ da distribui√ß√£o.
    - Al√©m disso, a amplitude (populacional) de muitas distribui√ß√µes que utilizaremos na pr√°tica √© infinita, ou n√£o √© bem definida.

- Uma outra possibilidade seria utilizarmos o _desvio padr√£o_ da distribui√ß√£o.
    - O desvio padr√£o √© uma medida do quanto, _em m√©dia_, as observa√ß√µes _est√£o distantes da m√©dia_.

#### Desvios em torno da m√©dia

- Para medir o qu√£o distante cada observa√ß√£o est√° da m√©dia, simplesmente tomamos a diferen√ßa entre aquela observa√ß√£o e a m√©dia.
    -   Essa quantidade √© conhecida como _desvio em torno da m√©dia_.
    -   Formalmente, se $X_i$ √© a $i$-√©sima observa√ß√£o da nossa amostra $\boldsymbol{X}$, definimos o _desvio de $X_i$ em torno da m√©dia amostral $\bar{X}$_ por $X_i - \bar{X}$, para $i = 1, \ldots, n$.

Considere ent√£o o seguinte exemplo:


```python
data = np.array([2, 3, 3, 9])
np.mean(data)
```




    4.25




```python
deviations = data - np.mean(data)
deviations
```




    array([-2.25, -1.25, -1.25,  4.75])



Cada entrada em `deviations` mede o desvio do elemento correspondente em `data` em torno da m√©dia (aqui, $\bar{X} = 4{,}25$).

E qual √© o "desvio m√©dio" (isto √©, a m√©dia dos desvios) nesse caso?


```python
np.mean(deviations)
```




    0.0



- **Fato**: a m√©dia dos desvios em torno da m√©dia √© _sempre igual a 0_, independente da distribui√ß√£o analisada!
    - Dessa forma, o desvio m√©dio em torno da m√©dia n√£o √© uma medida √∫til da dispers√£o de uma distribui√ß√£o.

#### Desvios em torno da m√©dia, **ao quadrado**

Vamos agora tomar o **quadrado** dos desvios em torno da m√©dia:


```python
## Elevando todos os desvios ao quadrado
deviations ** 2
```




    array([ 5.06,  1.56,  1.56, 22.56])



... e ent√£o tomar a m√©dia _dos desvios ao quadrado_, $(X_i - \bar{X})^2$:


```python
variance = np.mean(deviations ** 2)
variance
```




    7.6875



A quantidade calculada acima, isto √©, a _m√©dia dos desvios quadrados em torno da m√©dia_, √© conhecido como **vari√¢ncia**.

#### Raiz quadrada da soma dos quadrados?

- Apesar da vari√¢ncia ser uma medida muito √∫til de dispers√£o, em geral ela possui um problema de interpreta√ß√£o: a _unidade_ na qual a vari√¢ncia √© expressa n√£o √© igual √† de cada $X_i$, mas sim de $X_i^2$!   
- Por exemplo, se nossos dados est√£o em $\text{USD}$ ou $\text{BRL}$ (d√≥lares ou reais), a vari√¢ncia estar√° expressa em $\text{USD}^2$ ou $\text{BRL}^2$.
- Para contornar esse problema de interpretabilidade, tomamos ent√£o a _raiz quadrada_ da vari√¢ncia, e o resultado √© conhecido como **desvio padr√£o**.


```python
## O desvio padr√£o (DP) √© dado pela raiz quadrada da vari√¢ncia!
sd = variance ** 0.5
sd
```




    2.7726341266023544



#### Desvio padr√£o

- **Defini√ß√£o**: Raiz da m√©dia dos desvios (em torno da m√©dia) ao quadrado.
    - Usualmente denotamos a vari√¢ncia populacional por $\sigma^2$, o desvio padr√£o (DP) populacional por $\sigma$, e os an√°logos amostrais por $S$ e $S^2$.

Formalmente,

$$\begin{align*}
    S^2 &:= \frac{\sum^n_{i=1} (X_i - \bar{X})^2}{n}, & S &= \sqrt{S^2} = \sqrt{\frac{\sum^n_{i=1} (X_i - \bar{X})^2}{n}}.
\end{align*}$$

- O DP (que tamb√©m √© representado pela sigla em ingl√™s, SD, de _standard deviation_) mede o _qu√£o distantes_ os valores em uma distribui√ß√£o est√£o de sua m√©dia.
    - Equivalentemente, **o DP mede o qu√£o dispersos** os valores de uma distribui√ß√£o (em torno de sua m√©dia) s√£o.  
    - Dessa forma, quanto maior o DP, mais dispersos ser√£o os dados.
    - Lembre que, crucialmente, o desvio padr√£o √© _expresso nas mesmas unidades de $\boldsymbol{X}$_.

- A biblioteca `numpy` tem uma fun√ß√£o, `np.std`, que calcula o desvio padr√£o de um `Array`:


```python
np.std(data)
```




    2.7726341266023544



## Padroniza√ß√£o

### Exemplo: Alturas e pesos  üìè

Para motivar os conceitos dessa subse√ß√£o, vamos primeiro come√ßar com um conjunto de dados contendo as alturas (em polegadas) e pesos (em libras) de $n = 5,000$ homens adultos dos EUA:


```python
height_and_weight = pd.read_csv('data/height_and_weight.csv')
height_and_weight
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Height</th>
      <th>Weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>73.85</td>
      <td>241.89</td>
    </tr>
    <tr>
      <th>1</th>
      <td>68.78</td>
      <td>162.31</td>
    </tr>
    <tr>
      <th>2</th>
      <td>74.11</td>
      <td>212.74</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4997</th>
      <td>67.01</td>
      <td>199.20</td>
    </tr>
    <tr>
      <th>4998</th>
      <td>71.56</td>
      <td>185.91</td>
    </tr>
    <tr>
      <th>4999</th>
      <td>70.35</td>
      <td>198.90</td>
    </tr>
  </tbody>
</table>
<p>5000 rows √ó 2 columns</p>
</div>



### Distribui√ß√µes das alturas e pesos

Vamos analisar a distribui√ß√£o das vari√°veis do nosso conjunto.


```python
height_and_weight.plot(kind = 'hist', y = 'Height', density = True, ec = 'w', bins = 30, alpha = 0.8, figsize = (10, 5))
plt.ylabel("Densidade");
```


```python
height_and_weight.plot(kind = 'hist', y = 'Weight', density = True, ec = 'w', bins = 30, alpha = 0.8, color = 'C1', figsize = (10, 5))
plt.ylabel("Densidade");
```


```python
height_and_weight.plot(kind = 'hist', density = True, ec='w', bins = 60, alpha = 0.8, figsize = (10, 5))
plt.ylabel("Densidade");
```

**Observa√ß√£o**: As duas distribui√ß√µes acima s√£o similares √† vers√µes "deslocadas" e "esticadas" da mesma forma, denominada informalmente de **"curva de sino"** (_bell curve_) üîî.

Uma distribui√ß√£o com essa forma √© conhecida como **distribui√ß√£o Normal**.

### Unidades padronizadas

- Suponha que $X$ seja uma vari√°vel aleat√≥ria (num√©rica) com m√©dia $\mu$ e desvio padr√£o $\sigma$, e que $X_i$ seja um valor (realiza√ß√£o) dessa vari√°vel. Ent√£o,

\begin{align*}
    X_{i \: \text{(su)}} := \frac{X_i - \mu}{\sigma}
\end{align*}

representa $X_i$ em **unidades padronizadas**, $i = 1, \ldots, n$.

- Podemos interpretar os valores das unidades padronizadas $X_{i \: \text{(su)}}$ como sendo "o _n√∫mero de DPs que $X_i$ est√° de sua m√©dia_".
- Equivalentemente, se $X_{i \: \text{(su)}} = x \in \mathbb{R}$, ent√£o podemos dizer que $X_i$ est√° a $x$ DPs da sua m√©dia $\bar{X}$.

**Exemplo**: Suponha que uma pessoa pese 225 libras. Qual √© o seu peso em unidades padronizadas?


```python
weights = height_and_weight.get('Weight')
(225 - weights.mean()) / np.std(weights)
```

- Interpreta√ß√£o: 225 est√° a 1.92 desvios-padr√£o acima da m√©dia dos pesos.
- 225 libras √© igual a 1.92 em unidades padronizadas.

**Nota**: a padroniza√ß√£o sempre depende do valor de $\mu$ e $\sigma$, que s√£o _espec√≠ficos_ √† cada distribui√ß√£o. 

### Padroniza√ß√£o

- O processo de convers√£o dos valores de uma vari√°vel para unidades padronizadas √© conhecido como **padroniza√ß√£o**. 
- Consequentemente, os valores $X_{i \: \text{(su)}}$ obtidos atrav√©s da padroniza√ß√£o s√£o ditos **padronizados**.


```python
# Fun√ß√£o para padronizar as Series de um DataFrame.
def standard_units(col):
    return (col - col.mean()) / np.std(col)
```


```python
standardized_height = standard_units(height_and_weight.get('Height'))
standardized_height
```


```python
standardized_weight = standard_units(height_and_weight.get('Weight'))
standardized_weight
```

### O efeito da padroniza√ß√£o

Vari√°veis padronizadas sempre t√™m:
- M√©dia = 0.
- Vari√¢ncia = desvio padr√£o = 1.

√â comum padronizarmos diferentes vari√°veis simplesmente para termos todas na mesma escala durante a nossa an√°lise.


```python
# Lembrete: e-15 = 10^(-15), e assim em diante.
standardized_height.describe()
```


```python
standardized_weight.describe()
```

### Histogramas padronizados

Agora que padronizamos os pesos e as alturas, vamos ver mais uma vez como seus histogramas ficam lado-a-lado:


```python
standardized_height_and_weight = bpd.DataFrame().assign(
    Height=standardized_height,
    Weight=standardized_weight
)
standardized_height_and_weight.plot(kind = 'hist', density = True, ec = 'w',bins = 30, alpha = 0.8, figsize = (10, 5))
plt.ylabel("Densidade");
```

Ambas distribui√ß√µes s√£o bem parecidas! üëç

- Nota: embora a padroniza√ß√£o mude a loca√ß√£o e a escala de uma distribui√ß√£o, os percentis, frequ√™ncias e probabilidades **n√£o se alteram**.

## Resumo

- A m√©dia e a mediana s√£o medidas de tend√™ncia central.
- A vari√¢ncia e o desvio padr√£o (DP) s√£o medidas de dispers√£o.
    - O DP √© igual a raiz quadrada da vari√¢ncia.
    - Em linhas gerais, o desvio padr√£o mede, em m√©dia, o qu√£o distantes da m√©dia os valores de uma distribui√ß√£o est√£o.
- Para converter um valor $X_i$ para unidades padronizadas, fazemos $X_{i \: \text{(su)}} := \frac{X_i - \mu}{\sigma}$.
    - Valores em unidades padronizadas medem o n√∫mero de desvios padr√£o que $X_i$ est√° acima (ou abaixo) de sua m√©dia.
